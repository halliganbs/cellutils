{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f99bff41-faad-4a1a-8be6-c93da9a0a955",
   "metadata": {},
   "source": [
    "# XGBoost Regression Cell Microscopy Model example\n",
    "\n",
    "This notebook is an example workflow for generating an XGBoost Regression model for scoring 384-well cell plate assays from a randomized plate\n",
    "\n",
    "## Required Files\n",
    "\n",
    "- `data_cols` list of desired measurement columns, in this case a python pickle object\n",
    "- `Per_object.csv` a Cellprofiler measurement file of object level measurements\n",
    "- `Per_Image.csv` a Cellprofiler measurement file of Image level measurements, we will only be using the `ImageNumber`, `Image_Metadata_WellID` and `Image_Metadata_PlateID` columns for metadata\n",
    "- `Compounds.csv` a metadata csv containing needed metadata columns: `WellID`, `Compound`\n",
    "- Known names of the positive and negative controll compounds.\n",
    "\n",
    "## Step 1: Imports\n",
    "\n",
    "Imports for generating a scored mode\n",
    "\n",
    "- `os` and `re` Operating system for interacting with file paths and regex for pattern matching in strings\n",
    "- `numpy` and `pandas` tabular dataframes and interacting with the data\n",
    "- `sklearn` plate based normalization, train/validation split and model quality metrics\n",
    "- `xgb` Gradient boosted trees, the source for the model\n",
    "- `shap` Shapley analysis for feature importance\n",
    "- `matplotlib` and `seaborn` graphing utilities\n",
    "- `glob` for finding lists of file in a directory (needed for multiple plate models)\n",
    "- `cellutils.plot` plotting function for well level plates to include hits that are (6*std)+mean the compounds\n",
    "- `cellutils.utils` helper functions for reducing object level to well level means, generating a character range (e.g. A01->A24) for control lists, generating data cols based on typical measurement names and zprime for assay quality\n",
    "- `sqlite3` python sqlite 3 engine for using source Cellprofiler outputs\n",
    "- `pickle` package for saving/loading python objects in this case `data_cols`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ef7cc-5283-463c-8f75-c5a44a771735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import glob \n",
    "\n",
    "from cellutils.plot import plot_plate\n",
    "from cellutils.utils import make_well, char_range, get_data_cols, zprime\n",
    "\n",
    "import sqlite3\n",
    "import pickle\n",
    "\n",
    "#######################################\n",
    "### Change these paths to your data ###\n",
    "data_cols_path = 'path/to/data_cols'\n",
    "obj_path = 'path/to/object/file.csv'\n",
    "img_path = 'path/to/image/file.csv'\n",
    "meta_path  = 'path/to/meta/file.csv'\n",
    "#######################################\n",
    "\n",
    "with open(data_cols_path, 'rb') as f:\n",
    "    data_cols = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eab7c17-913b-4731-9f14-a45e6811493c",
   "metadata": {},
   "source": [
    "## Loading Data, Joining data, Preparing data\n",
    "\n",
    "We will read in the object data in chunks to save on memory during the read in\n",
    "\n",
    "- Read in all of the Data\n",
    "- Join metadata to data\n",
    "- Add `label` and `Condition` for later use\n",
    "\n",
    "Run both cells, the `head()` and `shape` prints at the end of the first is for sanity checking. The number of rows should not change but columns should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7715ba2a-8c68-4264-9212-e7410b5aeb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data read/join\n",
    "df = []\n",
    "for chunk in pd.read_csv(obj_path, chunksize=int(5e5)):\n",
    "    print(f\"Read {len(chunk)} rows...\")\n",
    "    df.append(chunk)\n",
    "del chunk # probably unneeded but just in case of memory issues\n",
    "df = pd.concat(df)\n",
    "meta = pd.read_csv(img_path, usecols=['ImageNumber', 'Image_Metadata_WellID', 'Image_Metadata_PlateID'])\n",
    "cmpds = pd.read_csv(meta_path)\n",
    "meta = pd.merge(meta, cmpds, left_on='Image_Metadata_WellID', right_on='WellID') # common issue in differing well_id column names, change as needed\n",
    "del cmpds # again memory issues, maybe\n",
    "\n",
    "print(df.shapel, meta.shape)\n",
    "df = pd.merge(df, meta, on='Image_Metadata_WellID', how='left') # the left is implied but occasionally this is needed\n",
    "print(df.shapel, meta.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55955d48-194b-48af-ad38-dfe180b98c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prepare\n",
    "#######################################\n",
    "####### Control Compound Names ########\n",
    "pc_name = 'good_drug'\n",
    "nc_name = 'no_drug_DMSO'\n",
    "#######################################\n",
    "\n",
    "# Condition column for plot coloring\n",
    "df['condition'] = 'cmpd'\n",
    "df.loc[df['compound']==pc_name, 'condition'] = 'pc'\n",
    "df.loc[df['compound']==nc_name, 'condition'] = 'nc'\n",
    "\n",
    "# dt will be our control data\n",
    "dt = df.loc[df['condition']!='cmpd']\n",
    "\n",
    "# label column for data training\n",
    "dt['label'] = 0\n",
    "dt.loc[dt['cond'] =='PC', 'label'] = 1\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57848d80-2429-4b90-96a2-582e77eed4ac",
   "metadata": {},
   "source": [
    "## Creating and training the Model\n",
    "\n",
    "- Define an X and Y for the model (scaled measurements and label)\n",
    "- Divide data into train and validate sets\n",
    "- Train the model and get quality metrics\n",
    "\n",
    "`evalset` is used for generating a loss curve (AUC, ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae181d8-5668-41b3-97df-a4ed035af885",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dt['label'].values\n",
    "X = StandardScaler().fit_transform(dt[data_cols])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "evalset = [(X_train, y_train), (X_test,y_test)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef7026b-dc41-471c-bc8e-937b19444a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "model.fit(X_train, y_train, eval_metric='logloss', eval_set=evalset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcea0f90-a98c-4d52-a93a-589d31f91aff",
   "metadata": {},
   "source": [
    "## Model Quality Metrics\n",
    "\n",
    "We have the model predict a label on the reserved validation (`test`) set to compare against naive data it hasn't been trained on\n",
    "\n",
    "### Metrics\n",
    "- Accuracy (score is rounded to 1 or 0 and compared to validation set)\n",
    "- R^2 (higher better nerver reaching 1)\n",
    "- Mean Squared Error (MSE) lower is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29913768-3803-4548-a1de-68374325964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "acc_preds = [round(val) for val in y_pred]\n",
    "ac = accuracy_score(y_test, acc_preds)\n",
    "\n",
    "r2 = r2_score(y_pred, y_test)\n",
    "mse = mean_squared_error(y_pred, y_test)\n",
    "\n",
    "print(\"IR500\")\n",
    "print(f\"Accuracy: {ac*100}%\")\n",
    "print(f\"R2:{r2:.3f}\")\n",
    "print(f\"MSE:{mse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e5e419-1a37-4e42-ab03-5d2eeead1322",
   "metadata": {},
   "source": [
    "### Loss/AUC/ROC\n",
    "\n",
    "Change names as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d629d-84fa-4577-b73e-0cbb80abf60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evals_result()\n",
    "plt.plot(results['validation_0']['logloss'], label='train')\n",
    "plt.plot(results['validation_1']['logloss'], label='test')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"IR500 AUC\")\n",
    "plt.savefig(\"plots/auc_ir500.svg\", format='SVG', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfabd4a-af02-4636-a188-e5e5af3542cc",
   "metadata": {},
   "source": [
    "## SHAP Analysis\n",
    "\n",
    "Shap is based on Shapely analysis is for which features are providing more to the aggregate of all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6585d26-46ad-4ec2-b66c-ee29de05e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer(X)\n",
    "shap.summary_plot(shap_values, X, feature_names=data_cols, show=False,)\n",
    "plt.savefig('plots/shap_ir500.png', format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cbc1ba-ff7f-4dd4-8745-f9ef43700acd",
   "metadata": {},
   "source": [
    "## Z-Prime\n",
    "\n",
    "Have the model predict the whole control set and calculate zprime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e536d1c-ddd6-4eeb-8aa0-6729ae3a300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['score'] = model.predict(X)\n",
    "pcs = dt.loc[dt['cond']=='PC', 'score']\n",
    "ncs = dt.loc[dt['cond']=='NC', 'score']\n",
    "zp = zprime(pcs, ncs)\n",
    "print(f\"Z-prime: {zp:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cded4d5-84bc-4245-9487-c098dceeb826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for future use\n",
    "model.save_model('models/ir500_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
